{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train YOLO-OBB**\n",
    "\n",
    "# YOLO用データセット準備スクリプト\n",
    "\n",
    "## 機能概要\n",
    "このスクリプトは物体検出用のYOLOv11モデルで使用するデータセットを準備します。\n",
    "\n",
    "## 主な処理\n",
    "1. **ディレクトリ構造の初期化**\n",
    "   - 既存のデータセットディレクトリを削除し、新規作成\n",
    "   - 訓練用と検証用のサブディレクトリを作成（画像用とラベル用）\n",
    "\n",
    "2. **データの分割**\n",
    "   - 画像ファイルをランダムに並べ替え\n",
    "   - 8:2の比率で訓練データと検証データに分割\n",
    "\n",
    "3. **ファイルのコピー**\n",
    "   - 画像ファイルを対応するディレクトリにコピー\n",
    "   - 対応するラベルファイルを検索してコピー\n",
    "   - ラベルファイルが見つからない場合は警告を表示\n",
    "\n",
    "4. **YAML設定ファイルの作成**\n",
    "   - データセットのパス情報\n",
    "   - クラス数（1：pupil）\n",
    "   - クラス名の定義\n",
    "\n",
    "## 出力情報\n",
    "- 訓練データファイル数\n",
    "- 検証データファイル数\n",
    "- 作成されたYAMLファイルのパス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データセットの準備が完了しました。\n",
      "訓練データ: 2833ファイル\n",
      "検証データ: 709ファイル\n",
      "YAMLファイル作成: C:\\Users\\CorneAI\\YOLOv11_modified_Mobius\\dataset\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "# パスの設定\n",
    "base_dir = r'C:\\Users\\CorneAI\\YOLOv11_modified_Mobius'\n",
    "dataset_dir = os.path.join(base_dir, 'dataset')\n",
    "images_dir = os.path.join(base_dir, 'images')\n",
    "labels_dir = os.path.join(base_dir, 'labels')\n",
    "\n",
    "# datasetフォルダが存在する場合は削除して新規作成\n",
    "if os.path.exists(dataset_dir):\n",
    "    shutil.rmtree(dataset_dir)\n",
    "os.makedirs(dataset_dir)\n",
    "\n",
    "# train, validフォルダの作成\n",
    "train_img_dir = os.path.join(dataset_dir, 'train', 'images')\n",
    "train_label_dir = os.path.join(dataset_dir, 'train', 'labels')\n",
    "valid_img_dir = os.path.join(dataset_dir, 'valid', 'images')\n",
    "valid_label_dir = os.path.join(dataset_dir, 'valid', 'labels')\n",
    "\n",
    "os.makedirs(train_img_dir)\n",
    "os.makedirs(train_label_dir)\n",
    "os.makedirs(valid_img_dir)\n",
    "os.makedirs(valid_label_dir)\n",
    "\n",
    "# 画像ファイル名のリストを取得\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "random.shuffle(image_files)  # ランダムに並び替え\n",
    "\n",
    "# 8:2の比率で分割するインデックスを計算\n",
    "split_idx = int(len(image_files) * 0.8)\n",
    "train_files = image_files[:split_idx]\n",
    "valid_files = image_files[split_idx:]\n",
    "\n",
    "# ファイルをtrainとvalidに分配\n",
    "for file in train_files:\n",
    "    # 画像ファイルのコピー\n",
    "    src_img = os.path.join(images_dir, file)\n",
    "    dst_img = os.path.join(train_img_dir, file)\n",
    "    shutil.copy2(src_img, dst_img)\n",
    "    \n",
    "    # 対応するラベルファイルの処理\n",
    "    # 拡張子を除いたファイル名を取得\n",
    "    base_name = os.path.splitext(file)[0]\n",
    "    label_file = base_name + '.txt'\n",
    "    src_label = os.path.join(labels_dir, label_file)\n",
    "    \n",
    "    # ラベルファイルが存在する場合のみコピー\n",
    "    if os.path.exists(src_label):\n",
    "        dst_label = os.path.join(train_label_dir, label_file)\n",
    "        shutil.copy2(src_label, dst_label)\n",
    "    else:\n",
    "        print(f\"警告: ラベルファイルが見つかりません: {label_file}\")\n",
    "\n",
    "for file in valid_files:\n",
    "    # 画像ファイルのコピー\n",
    "    src_img = os.path.join(images_dir, file)\n",
    "    dst_img = os.path.join(valid_img_dir, file)\n",
    "    shutil.copy2(src_img, dst_img)\n",
    "    \n",
    "    # 対応するラベルファイルの処理\n",
    "    base_name = os.path.splitext(file)[0]\n",
    "    label_file = base_name + '.txt'\n",
    "    src_label = os.path.join(labels_dir, label_file)\n",
    "    \n",
    "    # ラベルファイルが存在する場合のみコピー\n",
    "    if os.path.exists(src_label):\n",
    "        dst_label = os.path.join(valid_label_dir, label_file)\n",
    "        shutil.copy2(src_label, dst_label)\n",
    "    else:\n",
    "        print(f\"警告: ラベルファイルが見つかりません: {label_file}\")\n",
    "\n",
    "# yamlファイルの作成\n",
    "yaml_path = os.path.join(dataset_dir, 'data.yaml')\n",
    "yaml_content = {\n",
    "    'train': os.path.join(dataset_dir, 'train', 'images'),\n",
    "    'val': os.path.join(dataset_dir, 'valid', 'images'),\n",
    "    'nc': 1,  # クラス数\n",
    "    'names': {0: 'pupil',}  # クラス名\n",
    "}\n",
    "\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "\n",
    "print(\"データセットの準備が完了しました。\")\n",
    "print(f\"訓練データ: {len(train_files)}ファイル\")\n",
    "print(f\"検証データ: {len(valid_files)}ファイル\")\n",
    "print(f\"YAMLファイル作成: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! GPU: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# CUDAが使えるかどうかを確認\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if cuda_available:\n",
    "    print(f\"CUDA is available! GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import wget\n",
    "\n",
    "# モデルのロード\n",
    "import os\n",
    "\n",
    "model_path = 'yolo11n-obb.pt'\n",
    "if not os.path.exists(model_path):\n",
    "    # モデルが存在しない場合のみダウンロード\n",
    "    print(f\"{model_path}が見つからないため、ダウンロードします...\")\n",
    "    wget.download('https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-obb.pt')\n",
    "else:\n",
    "    print(f\"{model_path}が既に存在します。既存のモデルを使用します。\")\n",
    "\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(data=r\"C:\\Users\\CorneAI\\YOLOv11_modified_Mobius\\dataset\\data.yaml\", epochs=1000, imgsz=640)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# モデルのロード\n",
    "model = YOLO(\"path/to/best.pt\")  # あなたのカスタムモデルのパスを指定\n",
    "\n",
    "# 画像パス\n",
    "image_path = r\"C:\\Users\\CorneAI\\YOLOv11_modified_Mobius\\MOBIUS\\Images\\3\\3_1i_Lu_2.jpg\"\n",
    "\n",
    "# 画像パスからマスクパスを自動生成\n",
    "image_path_obj = Path(image_path)\n",
    "mask_path = str(image_path_obj).replace(\"Images\", \"Masks\").replace(\".jpg\", \".png\")\n",
    "print(f\"画像パス: {image_path}\")\n",
    "print(f\"マスクパス: {mask_path}\")\n",
    "\n",
    "# 推論実行\n",
    "results = model(image_path)\n",
    "\n",
    "# 結果を可視化するための準備\n",
    "original_img = cv2.imread(image_path)\n",
    "original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "mask_img = cv2.imread(mask_path)\n",
    "mask_img = cv2.cvtColor(mask_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 検出結果を描画\n",
    "result_img = original_img.copy()\n",
    "for result in results:\n",
    "    # OBBの取得\n",
    "    xyxyxyxy = result.obb.xyxyxyxy  # ポリゴン形式（4点）\n",
    "    \n",
    "    # クラス名と信頼度の取得\n",
    "    class_names = [result.names[cls.item()] for cls in result.obb.cls.int()]\n",
    "    confs = result.obb.conf\n",
    "    \n",
    "    # 検出したOBBを画像に描画\n",
    "    for i, box in enumerate(xyxyxyxy):\n",
    "        pts = box.cpu().numpy().astype(np.int32)\n",
    "        # ポリゴンを描画\n",
    "        cv2.polylines(result_img, [pts], True, (0, 255, 0), 2)\n",
    "        \n",
    "        # クラス名と信頼度を表示\n",
    "        label = f\"{class_names[i]} {confs[i]:.2f}\"\n",
    "        cv2.putText(result_img, label, (pts[0][0], pts[0][1] - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# 画像を並べて表示\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('元画像')\n",
    "plt.imshow(original_img)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('検出結果')\n",
    "plt.imshow(result_img)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('正解マスク')\n",
    "plt.imshow(mask_img)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
